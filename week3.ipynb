{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# WEEK 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In week 3, we worked on fixing bugs in the code. We built our convolution neural network model, and trained the model. We used 100 combinations that we scored for training data. We allocated 80 percent of this as training data, and the remaining 20 percent as testing data. We aimed to reduce the error by applying cross validation while training our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Traning Model\n",
    "While creating our last model, we encountered the error of mismatching the sizes of the photos, so we made a function that would make the size of the photos the same in all of them. We changed the size of all photos to (150,150,3). We also normalized all pixels by dividing them by 255. Thanks to this, there was an increase in performance.\n",
    "\n",
    "A series of convolutional and pooling layers are added to define the convolutional neural network (CNN) architecture. Each convolution layer is intended to extract image features using a certain number of filters. \"relu\" was used as the activation function.\n",
    "\n",
    "First convolution layer: 32 filters, 3x3 filter matrix\n",
    "First pooling layer: 2x2 maximum pooling\n",
    "Second convolution layer: 64 filters, 3x3 filter matrix\n",
    "Second pooling layer: maximum pooling of size 2x2\n",
    "Third convolution layer: 128 filters, 3x3 filter matrix\n",
    "Third pooling layer: maximum pooling of size 2x2\n",
    "\n",
    "Then we determined the inputs and outputs of the model. In short, the model takes vectors from two different photographs and produces a score based on them.\n",
    "\n",
    "As a result of training the model, we got the results of loss: 10.6359 - val_loss: 12.2469 after 10 epochs. In the last epoch, the training loss is observed to be quite low (10.6359) and the validation loss to be low (12.2469). This means we can say that the model performs well on the training data and has generalization ability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to take our data set from trendyol.com, one of the largest online shopping sites in Turkey. Although we can do this with libraries such as beautifulsoup, we decided to download the photos on the page both ethically and in order to access the files. As we thought before, we divided the photos into trousers and t-shirts and thus created our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting The Score of Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the training process, our model is ready to make predictions. After removing the photos we used for scoring, we entered the remaining photos into the model and got a prediction value.\n",
    "\n",
    "We made all possible combinations and placed the scores in a data frame. The scores we obtained were not what we expected, but the photos given were close to our preferences.\n",
    "\n",
    "Firstly, the scores we obtained were between 1 and 3. These were far from our expectations. After a few optimizations, the highest score we could get was approximately 5.5, but the clothes were compatible with our preferences."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
